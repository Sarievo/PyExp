{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying_cost maintenance_cost doors capacity luggage safety acceptability  \\\n",
      "0       vhigh              low     4        4   small    med         unacc   \n",
      "1       vhigh              med     3        4   small   high           acc   \n",
      "2         med             high     3        2     med   high         unacc   \n",
      "3         low              med     4     more     big    low         unacc   \n",
      "4         low             high     2     more     med   high           acc   \n",
      "\n",
      "  manufacturer_country  \n",
      "0                China  \n",
      "1               France  \n",
      "2        United States  \n",
      "3        United States  \n",
      "4          South Korea  \n",
      "Japan            0.228\n",
      "Germany          0.218\n",
      "South Korea      0.159\n",
      "United States    0.138\n",
      "Italy            0.097\n",
      "France           0.087\n",
      "China            0.073\n",
      "Name: manufacturer_country, dtype: float64\n",
      "\n",
      "The country with 4th frequency: United States\n",
      "Japan's frequency: 22.8%\n",
      "['vhigh' 'med' 'low' 'high']\n",
      "med\n",
      "small    0.339\n",
      "med      0.333\n",
      "big      0.328\n",
      "Name: luggage, dtype: float64\n",
      "\n",
      "small    0.339\n",
      "med      0.333\n",
      "big      0.328\n",
      "Name: luggage, dtype: float64\n",
      "Car with 5+ doors: 24.6%\n"
     ]
    }
   ],
   "source": [
    "## for more info about the data:\n",
    "# https://archive.ics.uci.edu/ml/datasets/car+evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "car_eval = pd.read_csv('car_eval_dataset.csv')\n",
    "print(car_eval.head())\n",
    "\n",
    "manufacturer_countries = car_eval['manufacturer_country']\n",
    "countries_proportion = manufacturer_countries.value_counts(normalize = True, dropna = True)\n",
    "print(countries_proportion)\n",
    "print(\"\\nThe country with 4th frequency: \" + countries_proportion.index[3])\n",
    "print(\"Japan's frequency: \" + str(countries_proportion['Japan'] * 100) + \"%\")\n",
    "\n",
    "buying_cost = car_eval['buying_cost'].unique()\n",
    "print(buying_cost)\n",
    "buying_cost_categories = ['low', 'med', 'high', 'vhigh']\n",
    "car_eval['buying_cost'] = pd.Categorical(\n",
    "    car_eval['buying_cost'],\n",
    "    buying_cost_categories,\n",
    "    ordered = True\n",
    ")\n",
    "\n",
    "buying_cost_median = np.median(car_eval['buying_cost'].cat.codes)\n",
    "print(buying_cost_categories[int(buying_cost_median)])\n",
    "\n",
    "luggage_proportion = car_eval['luggage'].value_counts(normalize = True, dropna = True)\n",
    "print(luggage_proportion)\n",
    "luggage_proportion = car_eval['luggage'].value_counts(normalize = True, dropna = False)\n",
    "print()\n",
    "print(luggage_proportion)\n",
    "\n",
    "car_doors = car_eval['doors']\n",
    "doors_proportion = (car_doors == '5more').mean()\n",
    "print(\"Car with 5+ doors: \" + str(doors_proportion * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "car_eval = pd.read_csv('car_eval_dataset.csv')\n",
    "\n",
    "# Task Group 1\n",
    "\n",
    "# 1. Create a table of frequencies of all the cars reviewed by \"manufacturer_country\".\n",
    "# What is the modal category? Which country appears 4th most frequently?\n",
    "\n",
    "# Note: `.value_counts()` produces a table of frequencies in order, you can reference the\n",
    "# N-th row of this table to find the Nth most common value in the data. In this case, it's Germany and the US...\n",
    "print(car_eval.manufacturer_country.value_counts())\n",
    "\n",
    "# 2. Calculate a table of proportions for countries that appear in \"manufacturer_country\" in the dataset.\n",
    "\n",
    "# Note: Using normalize w. `.value_counts()` normalizes the table of frequencies that `.value_counts() produces by default to a table of proportions. A table of frequencies takes the count of observations, a table of proportions takes the proportion each value represents of the total.\n",
    "print(car_eval.manufacturer_country.value_counts(normalize=True))\n",
    "\n",
    "# Japan            0.228\n",
    "\n",
    "\n",
    "# Task Group 2\n",
    "\n",
    "# 3. \"buying_cost\" is a categorical variable which describes the cost of buying any car in the dataset.\n",
    "# Note: The `.unique()` method strips all unique values from a column.\n",
    "\n",
    "print(car_eval[\"buying_cost\"].unique())\n",
    "\n",
    "# 4. Create a list of the unique categories in from lowest to highest\n",
    "# cost in the \"buying_cost\" variable.\n",
    "\n",
    "# NOTE: Learner just needs to create their own list and save it for use in\n",
    "# subsequent steps\n",
    "buying_cost_categories = ['low', 'med', 'high', 'vhigh']\n",
    "print(buying_cost_categories)\n",
    "\n",
    "# 5. Convert `buying_cost` to type `'category'` using the order created in the previous\n",
    "# exercise.\n",
    "\n",
    "# Note: You can convert a field to type category using the function `pandas.Categorical()`. The pandas categorical type allows us to perform numeric operations on categorical data.\n",
    "\n",
    "# You can also check the column has type category by checking `print(car_eval.buying_cost)` The output out that should note the column type (see below)\n",
    "\n",
    "car_eval[\"buying_cost\"] = pd.Categorical(\n",
    "    car_eval[\"buying_cost\"],\n",
    "    buying_cost_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(car_eval.buying_cost)\n",
    "\n",
    "# Name: buying_cost, Length: 1000, dtype: category\n",
    "# Categories (4, object): [low < med < high < vhigh]\n",
    "\n",
    "# 6. Calculate the median category of the `buying_cost` variable.\n",
    "\n",
    "# Note: In Python, you can use `np.median()` to calculate the median value of a numerical series. In this case, you also must access the numerical values of the categories. This can be done with the `.cat.codes` attribute.\n",
    "\n",
    "\n",
    "median_category_num = np.median(car_eval['buying_cost'].cat.codes)\n",
    "print(median_category_num)\n",
    "\n",
    "median_category = buying_cost_categories[int(median_category_num)]\n",
    "print(median_category)\n",
    "\n",
    "# Task Group 3\n",
    "\n",
    "# 7. Calculate a table of proportions for 'luggage'.\n",
    "\n",
    "# Note: Using normalize w. `.value_counts()` normalizes the\n",
    "# table of frequencies that `value_counts() produces by default\n",
    "# to a table of proportions\n",
    "print(car_eval.luggage.value_counts(normalize=True))\n",
    "\n",
    "# 8. Are there any missing values in this column? Replicate the table of proportions from the previous exercise, but do not exclude any missing values from the count.\n",
    "\n",
    "# Note: Using `.value_counts()`, missing values are removed by default. To keep missing values in the summary you can pass `dropna = False` to `.value_counts()`. If the result using `dropna = False` is the same, then you can conclude there are no missing values. In this case, we see they are the same.\n",
    "\n",
    "print(car_eval.luggage.value_counts(dropna=False, normalize=True))\n",
    "\n",
    "\n",
    "# 9. Without passing `normalize = True` to `.value_counts()`,\n",
    "# can you replicate the result you got in the previous exercise?\n",
    "\n",
    "# Note: This method relies on `luggage` having no null values.\n",
    "# If a field does have nulls The below is a more robust solution,\n",
    "# using the `.count()` method excludes NULLs in the denominator just\n",
    "# as `.value_counts(normalize=True)` does\n",
    "\n",
    "print(car_eval.luggage.value_counts()/len(car_eval.luggage))\n",
    "\n",
    "# Safe alternative if there are Nulls:\n",
    "car_eval.luggage.value_counts()/car_eval.luggage.count()\n",
    "\n",
    "# Task Group 4\n",
    "\n",
    "# 10/11. Find the frequency and proportion of cars that have 5 or more doors.\n",
    "\n",
    "# Note: You must first create a series that evaluates to true/false values.\n",
    "# Then, by calling .sum() and .mean() on this series the value and count of\n",
    "# `True`/1 values are calculated\n",
    "\n",
    "\n",
    "frequency = (car_eval.doors == '5more').sum()\n",
    "proportion = (car_eval.doors == '5more').mean()\n",
    "print(frequency)\n",
    "print(proportion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}